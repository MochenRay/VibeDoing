# AI产品评估指标：全景导论

> **源真理版本**：v1.0 (AI生成，基于2025-2026年最新实践)
> **项目定位**：核心补齐——量化思维，面试必考

---

## 一、为什么 AI 产品经理必须懂评估指标？

| 场景 | 为什么需要懂指标 |
|------|-----------------|
| **需求定义** | 「模型准确率要达到多少才能上线？」 |
| **方案评审** | 「为什么选召回率而不是精确率？」 |
| **效果验收** | 「这个 AI 功能效果好不好，怎么衡量？」 |
| **成本控制** | 「用 GPT-4 还是 GPT-3.5？成本差多少？」 |
| **面试答辩** | 「风险预警系统应该优先保哪个指标？」 |

---

## 二、混淆矩阵与基础指标

### 2.1 混淆矩阵（Confusion Matrix）

对于二分类问题（是/否、正/负），混淆矩阵描述预测结果与真实标签的关系：

```
                    预测结果
                 正例(Positive)  负例(Negative)
真实    正例(P)      TP              FN
标签    负例(N)      FP              TN
```

| 术语 | 含义 | 举例（火灾检测）|
|------|------|----------------|
| **TP** (True Positive) | 预测正确的正例 | 真的有火，系统报警了 |
| **TN** (True Negative) | 预测正确的负例 | 没有火，系统没报警 |
| **FP** (False Positive) | 误报 | 没有火，系统报警了（虚警）|
| **FN** (False Negative) | 漏报 | 真的有火，系统没报警（漏警）|

### 2.2 四个核心指标

**准确率（Accuracy）**：整体预测对了多少
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**精确率（Precision）**：报警的里面，有多少是真的
```
Precision = TP / (TP + FP)
```
> 直觉：精确率高 = 误报少 = 「报警就是真的」

**召回率（Recall）**：真正的正例，被找出来多少
```
Recall = TP / (TP + FN)
```
> 直觉：召回率高 = 漏报少 = 「真的都能被发现」

**F1 Score**：精确率和召回率的调和平均
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```
> 直觉：F1 平衡了精确率和召回率

### 2.3 手算练习

**场景**：火灾检测系统，100次实际情况：
- 真实火灾 20 次，系统报警 18 次
- 无火灾 80 次，系统报警 10 次

**计算**：
```
TP = 18（真的有火且报警）
FN = 2（真的有火但没报警）
FP = 10（没有火但报警）
TN = 70（没有火且没报警）

Accuracy = (18 + 70) / 100 = 88%
Precision = 18 / (18 + 10) = 64.3%
Recall = 18 / (18 + 2) = 90%
F1 = 2 × (0.643 × 0.9) / (0.643 + 0.9) = 75%
```

---

## 三、业务场景下的指标选择

### 3.1 核心问题：精确率 vs 召回率

精确率和召回率往往是此消彼长的关系（tradeoff）。不同业务场景，优先级不同：

| 场景 | 优先指标 | 理由 |
|------|---------|------|
| **风险预警**（火灾、安全） | 召回率 | 宁可多报不能漏报，漏报代价太大 |
| **内容推荐** | 精确率 | 推荐不准用户会流失 |
| **垃圾邮件过滤** | 精确率 | 误删重要邮件代价大 |
| **疾病筛查** | 召回率 | 漏诊可能危及生命 |
| **欺诈检测** | 召回率（初筛）+ 精确率（复核）| 两阶段策略 |

### 3.2 面试经典问题

**问题**：风险预警系统优先保精确率还是召回率？

**标准答案**：
> 「优先保召回率。因为风险预警的核心目标是『不漏报』，漏报一次真实风险可能造成重大损失（火灾、人员伤亡）。而误报的代价相对较小（多出动一次、多核查一次）。所以宁可多报、不能漏报。
>
> 当然，召回率也不是越高越好。如果误报率太高（精确率太低），会导致『狼来了』效应，让用户不再信任系统。所以实际中会设定一个召回率下限（比如95%），在此基础上尽可能提高精确率。」

---

## 四、Token 成本计算

### 4.1 Token 计费逻辑

大模型 API 按 Token 计费：
- **输入 Token**：你发给模型的内容
- **输出 Token**：模型返回的内容
- 通常输出 Token 比输入贵（2-4倍）

**中文 Token 估算**：
- 1个汉字 ≈ 0.7-1 个 Token
- 500 字中文 ≈ 350-500 Token

### 4.2 主流模型价格（2026年1月）

| 模型 | 输入价格 | 输出价格 | 备注 |
|------|---------|---------|------|
| GPT-4o | $2.50/1M tokens | $10.00/1M tokens | 主力模型，性价比提升 |
| GPT-4o Mini | $0.15/1M tokens | $0.60/1M tokens | 轻量任务首选 |
| Claude Opus 4.5 | $5.00/1M tokens | $25.00/1M tokens | 推理最强 |
| Claude Sonnet 4.5 | $3.00/1M tokens | $15.00/1M tokens | 平衡选择 |
| 文心一言 4.5 Turbo | ¥0.004/千tokens | ¥0.008/千tokens | 国内首选 |
| 通义千问 Qwen3 | 按量计费 | - | 开源可私有化 |

### 4.3 成本估算案例

**场景**：AI 客服系统
- 日活用户：10,000
- 人均对话：5 轮
- 每轮 Token：输入 200 + 输出 500 = 700

**计算（用 GPT-4o）**：
```
日 Token 总量 = 10,000 × 5 × 700 = 35,000,000 tokens = 35M tokens

日成本 = 输入成本 + 输出成本
       = (35M × 200/700) × $2.50/1M + (35M × 500/700) × $10.00/1M
       = 10M × $2.50/1M + 25M × $10.00/1M
       = $25 + $250
       = $275/天 ≈ ¥2,000/天

月成本 ≈ ¥60,000
```

**如果换 GPT-4o Mini**：
```
日成本 = 10M × $0.15/1M + 25M × $0.60/1M
       = $1.5 + $15
       = $16.5/天 ≈ ¥120/天

月成本 ≈ ¥3,600
```

> **成本差异**：GPT-4o 比 GPT-4o Mini 贵约 17 倍，但相比旧版 GPT-4 Turbo 已大幅降价

---

## 五、响应时间与用户体验

### 5.1 时间阈值

| 响应时间 | 用户感受 | 适用场景 |
|---------|---------|---------|
| < 1秒 | 优秀，即时反馈 | 简单查询、分类 |
| 1-3秒 | 可接受，有等待感 | 中等复杂任务 |
| 3-5秒 | 需要加载动画 | 复杂生成任务 |
| > 5秒 | 明显等待，流失风险 | 需要特殊设计 |

### 5.2 优化策略

**Streaming（流式输出）**：
- 不等全部生成完再返回
- 边生成边显示
- 「首字时间」比「完成时间」更重要

**预期管理**：
- 告诉用户大概需要等多久
- 显示进度或加载动画
- 提供取消选项

---

## 六、A/B 测试设计

### 6.1 为什么需要 A/B 测试？

AI 产品的效果很难仅通过指标判断，需要在真实用户上验证：
- 新 Prompt 真的比旧的好吗？
- 这个 AI 功能上线后用户满意度会提升吗？
- 成本降低后效果下降多少？

### 6.2 A/B 测试核心要素

| 要素 | 说明 | 示例 |
|------|------|------|
| **分组** | 随机分配用户到实验组/对照组 | 50% 用户用新 Prompt |
| **指标** | 衡量效果的核心指标 | 满意度、准确率、转化率 |
| **样本量** | 需要多少用户才能得出可靠结论 | 根据效果差异和置信度计算 |
| **周期** | 实验持续多长时间 | 1-2周，覆盖完整用户周期 |

### 6.3 A/B 测试方案模板

```markdown
# A/B 测试方案

## 实验背景
[描述为什么要做这个实验]

## 实验假设
[假设新方案在某个指标上会有 X% 的提升]

## 分组设计
- 对照组 (Control): [原方案]
- 实验组 (Treatment): [新方案]
- 分流比例: 50% / 50%
- 分流方式: 按用户ID哈希

## 核心指标
- 主指标: [最重要的衡量标准]
- 辅助指标: [其他观察指标]
- 护栏指标: [不能恶化的底线指标]

## 样本量估算
- 预期效果差异: [X%]
- 置信度: 95%
- 统计功效: 80%
- 所需样本量: [计算结果]

## 实验周期
- 开始时间: [日期]
- 预计结束: [日期]
- 中间检查: [日期]

## 决策标准
- 如果主指标提升 > X% 且统计显著，则推全
- 如果护栏指标恶化 > Y%，则终止实验
```

---

## 七、综合应用：火灾预警评估方案

### 7.1 评估维度

| 维度 | 指标 | 目标值 |
|------|------|-------|
| **检测效果** | 召回率 | ≥ 95%（不漏报）|
| **检测效果** | 精确率 | ≥ 70%（不滥报）|
| **响应速度** | 报警延迟 | ≤ 30秒 |
| **系统稳定** | 可用性 | ≥ 99.9% |
| **运营成本** | 月API成本 | ≤ 预算 |

### 7.2 评估方法

```markdown
# 森林火灾风险预警系统效果评估方案

## 一、评估目标
验证 AI 火灾检测模块的效果，确保满足上线标准

## 二、数据准备
- 历史火灾事件：200例（标注真实火灾）
- 非火灾事件：800例（各类干扰场景）
- 时间范围：近1年数据

## 三、核心指标

### 3.1 检测效果
| 指标 | 计算方式 | 目标 | 底线 |
|------|---------|------|------|
| 召回率 | TP / (TP + FN) | ≥95% | ≥90% |
| 精确率 | TP / (TP + FP) | ≥70% | ≥50% |
| F1 | 2×P×R/(P+R) | ≥80% | ≥65% |

### 3.2 响应性能
| 指标 | 计算方式 | 目标 | 底线 |
|------|---------|------|------|
| 平均延迟 | mean(响应时间) | ≤30s | ≤60s |
| P99延迟 | 99分位响应时间 | ≤60s | ≤120s |

### 3.3 成本估算
| 项目 | 计算 | 预估 |
|------|------|------|
| 日检测次数 | 监控点×检测频率 | 100,000次 |
| 单次Token | 输入+输出 | 500 tokens |
| 日成本 | 次数×Token×单价 | ¥XXX |

## 四、测试计划

### 4.1 离线测试
- 使用历史数据评估模型效果
- 生成混淆矩阵和各项指标

### 4.2 在线灰度
- 10% 流量灰度上线
- 观察1周，对比人工复核结果
- 指标达标后逐步放量

## 五、决策标准
- 召回率 ≥ 95% 且精确率 ≥ 70%：通过，推全
- 召回率 ≥ 90% 但精确率 < 70%：优化后重测
- 召回率 < 90%：不通过，需重新训练
```

---

## 八、学习节点说明

基于以上内容，本项目划分为 6 个学习节点：

### A层：基础指标

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **A1** | 混淆矩阵与基础指标：理解 TP/TN/FP/FN，能手算 P/R/F1 🚧 | 用森林火灾数据手算 P/R/F1，并解释每个数字的业务含义 |
| **A2** | 业务场景下的指标选择：理解不同场景的指标优先级 | 给 3 个 ToG 场景判断指标优先级并论述 |

### B层：产品指标

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **B1** | Token 成本计算：理解计费逻辑，能估算成本 | 为城市大脑某 AI 功能做成本估算（含模型选型对比）|
| **B2** | 响应时间与用户体验：理解时间阈值和优化策略 | 为风险预警场景设计响应时间要求并说明理由 |
| **B3** | A/B 测试设计：掌握测试方案设计 | 为某 AI 功能写完整 A/B 测试方案 |

### C层：综合应用

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **C1** | 综合：火灾预警评估方案 | 《效果评估方案》文档 |

---

## 九、思考问题

读完这篇导论，尝试不看上文回答：

1. **精确率和召回率分别衡量什么？在风险预警场景下，应该优先保哪个？为什么？**

2. **如果日活1万用户，人均5次对话，每次700 Token，用 GPT-4 Turbo，月成本大约多少？**

3. **设计一个 A/B 测试需要考虑哪些核心要素？**

---

> **下一步**：进入 A1 节点，学习混淆矩阵与基础指标的计算。
