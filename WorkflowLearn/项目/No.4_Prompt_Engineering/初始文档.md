# Prompt Engineering：全景导论

> **源真理版本**：v1.2 (AI生成，2026年1月更新)
> **更新内容**：System Prompt、Structured Output API、Tool Use、Thinking Mode、DSPy 认知
> **项目定位**：核心补齐——AI产品经理最重要的实操能力

---

## 一、什么是 Prompt Engineering？

**Prompt**（提示词）是你与大模型沟通的方式。**Prompt Engineering**（提示词工程）是通过设计更好的提示词，让模型输出更符合预期的结果。

> **核心认知**：大模型的能力是固定的，但通过不同的 Prompt，可以激发出截然不同的效果。Prompt Engineering 不是「哄骗」模型，而是「精准沟通」。

---

## 二、为什么 AI 产品经理必须掌握 Prompt Engineering？

| 场景 | 为什么需要 Prompt |
|------|------------------|
| **产品设计** | 定义 AI 功能的输入输出格式、控制生成质量 |
| **原型验证** | 快速测试想法是否可行，不依赖开发 |
| **与开发沟通** | 能说清楚「模型应该怎么工作」 |
| **效果调优** | 发现问题时，能判断是 Prompt 问题还是模型问题 |
| **面试展示** | 这是 AI 产品经理面试的必考技能 |

---

## 三、Prompt 的基本结构

一个完整的 Prompt 通常包含以下要素：

```
┌─────────────────────────────────────────────────────────────┐
│  1. 角色设定 (Role)                                          │
│     告诉模型「你是谁」                                        │
├─────────────────────────────────────────────────────────────┤
│  2. 任务描述 (Task)                                          │
│     告诉模型「要做什么」                                      │
├─────────────────────────────────────────────────────────────┤
│  3. 输入说明 (Input)                                         │
│     告诉模型「会收到什么」                                    │
├─────────────────────────────────────────────────────────────┤
│  4. 输出格式 (Output Format)                                 │
│     告诉模型「怎么输出」                                      │
├─────────────────────────────────────────────────────────────┤
│  5. 约束条件 (Constraints)                                   │
│     告诉模型「不能做什么」「必须遵守什么」                     │
├─────────────────────────────────────────────────────────────┤
│  6. 示例 (Examples) [可选]                                   │
│     告诉模型「参考这个格式」                                  │
└─────────────────────────────────────────────────────────────┘
```

### 示例：投诉分类 Prompt

```markdown
# 角色
你是一个客服投诉分类专家。

# 任务
根据用户投诉内容，判断投诉类别。

# 输入
用户投诉文本

# 输出格式
JSON格式：
{
  "category": "类别名称",
  "confidence": "high/medium/low",
  "reason": "判断理由"
}

# 类别选项
- 产品质量
- 物流配送
- 售后服务
- 价格问题
- 其他

# 约束
- 必须从上述5个类别中选择
- 如果无法确定，选择"其他"并说明原因
- confidence 根据文本明确程度判断

# 示例
输入："买的手机屏幕有划痕，明显是二手货"
输出：
{
  "category": "产品质量",
  "confidence": "high",
  "reason": "用户明确提到产品有物理缺陷（屏幕划痕）"
}
```

---

## 四、System Prompt 架构（2025-2026 新范式）

### 4.1 什么是 System Prompt？

**System Prompt** 是发送给模型的系统级指令，与用户消息（User Message）分离。这是 2024 年以来主流模型（Claude、GPT）强调的架构模式。

```
┌─────────────────────────────────────────────────────────────┐
│  System Prompt（系统级）                                     │
│  - 定义 AI 的身份、能力边界、行为规范                         │
│  - 优先级高于用户消息                                        │
│  - 在整个对话中持续生效                                      │
├─────────────────────────────────────────────────────────────┤
│  User Message（用户级）                                      │
│  - 用户的具体问题或指令                                      │
│  - 每轮对话可能不同                                          │
├─────────────────────────────────────────────────────────────┤
│  Assistant Message（助手级）                                 │
│  - 模型的回复                                                │
└─────────────────────────────────────────────────────────────┘
```

### 4.2 System Prompt vs 传统 Role 设定

| 维度 | 传统 Role（写在 Prompt 里） | System Prompt（API 层面分离） |
|------|---------------------------|------------------------------|
| **优先级** | 和其他内容同等 | 高于用户消息 |
| **持久性** | 需要每轮重复 | 在整个对话中持续生效 |
| **安全性** | 容易被 Prompt 注入攻击 | 更难被用户消息覆盖 |
| **复用性** | 需要复制粘贴 | 可以在产品层面统一配置 |

### 4.3 System Prompt 设计模板

```markdown
## 身份与能力
你是 [角色名称]，专门负责 [核心职责]。

## 行为规范
- 必须：[必须遵守的规则]
- 禁止：[绝对不能做的事]
- 边界：[能力范围说明]

## 输出格式
[默认的输出格式要求]

## 特殊情况处理
- 如果 [情况A]，则 [处理方式A]
- 如果无法确定，则 [兜底处理]
```

### 4.4 示例：城市事件分类助手

**System Prompt**：
```markdown
## 身份
你是12345热线的事件分类助手，负责将市民来电自动分类到对应部门。

## 行为规范
- 必须：从指定的部门列表中选择，不能自创类别
- 必须：给出分类置信度（高/中/低）
- 禁止：直接回答市民的问题（你只负责分类，不负责解答）
- 边界：只处理分类任务，其他问题回复「这不在我的职责范围内」

## 输出格式
JSON 格式，包含 department、confidence、reason 三个字段

## 部门列表
1. 城管执法局
2. 住建局
3. 交通运输局
4. 市场监管局
5. 生态环境局
6. 其他（需说明原因）

## 特殊情况
- 如果涉及多个部门，选择最相关的主责部门
- 如果完全无法判断，选择「其他」并说明原因
```

**User Message**：
```
市民来电：我们小区门口的路灯坏了三天了，晚上很黑很危险
```

> **要点**：System Prompt 定义了「这个 AI 是谁」「能做什么」「怎么输出」，而 User Message 只包含具体的用户输入。

---

## 五、Few-shot Learning：用示例教模型

### 4.1 什么是 Few-shot？

**Few-shot Learning** 是通过在 Prompt 中提供少量示例（通常 2-5 个），让模型学会特定的输出格式或判断标准。

```
Zero-shot：不给示例，直接让模型做
One-shot：给1个示例
Few-shot：给2-5个示例
```

### 4.2 为什么 Few-shot 有效？

大模型擅长「模式识别」。当你给出示例时，模型会：
1. 识别示例中的输入输出模式
2. 将这个模式应用到新输入上
3. 生成符合模式的输出

### 4.3 示例设计原则

| 原则 | 说明 | 反例 |
|------|------|------|
| **多样性** | 示例要覆盖不同情况 | 3个示例都是同类型 |
| **边界覆盖** | 包含边界case和特殊情况 | 只给简单case |
| **格式一致** | 所有示例输出格式完全一致 | 示例格式不统一 |
| **顺序考量** | 把最典型的示例放前面 | 特殊case放第一个 |

### 4.4 Few-shot 示例

```markdown
# 任务
判断句子的情感倾向

# 示例
输入："这个产品太棒了，强烈推荐！"
输出：正面

输入："质量一般，不值这个价格"
输出：负面

输入："还行吧，中规中矩"
输出：中性

输入："物流很快但包装有点破损"
输出：中性

# 现在判断
输入："{用户输入}"
输出：
```

---

## 五、结构化输出控制

### 5.1 为什么需要结构化输出？

在产品中，AI 的输出通常需要被下游系统处理：
- 需要解析字段 → 必须是 JSON
- 需要展示格式 → 必须是 Markdown
- 需要调用 API → 必须符合 Schema

### 5.2 JSON 输出控制技巧

**明确要求格式**：
```markdown
输出必须是合法的 JSON 格式，不要包含任何其他文字。
```

**提供 Schema**：
```markdown
按以下 JSON Schema 输出：
{
  "title": "string, 标题",
  "summary": "string, 100字以内摘要",
  "tags": ["string", "标签数组，最多5个"]
}
```

**给出完整示例**：
```markdown
输出示例：
{
  "title": "关于XX的报告",
  "summary": "本报告主要分析了...",
  "tags": ["分析", "报告", "XX领域"]
}
```

### 5.3 常见失败模式及修复

| 失败模式 | 原因 | 修复方法 |
|---------|------|---------|
| 输出包含多余文字 | 模型「客气」地加了解释 | 明确说「只输出JSON，不要其他文字」|
| JSON 格式错误 | 引号、逗号问题 | 给出正确示例，强调「合法JSON」|
| 字段缺失 | 模型「忘了」某个字段 | 在 Schema 中标注「必填」|
| 数组长度不对 | 没有限制 | 明确说「最多/最少 N 个」|

### 6.4 验证标准

**10次至少9次格式正确**：
- 同一个 Prompt 测试 10 次
- 至少 9 次输出格式完全正确
- 如果达不到，优化 Prompt 直到达标

---

## 七、Structured Output API（2025-2026 新范式）

### 7.1 什么是 Structured Output API？

2025 年起，主流模型都提供了**原生的结构化输出 API**，可以强制模型按照指定的 JSON Schema 输出，而不是依赖 Prompt 约束。

| 模型 | 功能名称 | 特点 |
|------|---------|------|
| **Claude** | Tool Use + JSON Schema | 通过工具定义强制输出格式 |
| **OpenAI** | JSON Mode / Structured Outputs | 强制输出合法 JSON |
| **Gemini** | Structured Output | 支持复杂嵌套结构 |

### 7.2 Prompt 方式 vs API 方式

| 维度 | Prompt 方式（传统） | Structured Output API |
|------|-------------------|----------------------|
| **稳定性** | 90%（需要反复调试） | 99%+（API 层面保证） |
| **复杂度** | 需要写详细的格式说明 | 只需定义 Schema |
| **错误处理** | 需要程序端解析和容错 | API 直接返回结构化数据 |
| **适用场景** | 简单输出、快速原型 | 生产环境、复杂结构 |

### 7.3 示例：使用 Claude Tool Use 实现结构化输出

```python
# 定义输出结构（Tool 定义）
tools = [{
    "name": "classify_event",
    "description": "对城市事件进行分类",
    "input_schema": {
        "type": "object",
        "properties": {
            "department": {
                "type": "string",
                "enum": ["城管执法局", "住建局", "交通运输局", "市场监管局", "其他"],
                "description": "负责处理的部门"
            },
            "confidence": {
                "type": "string",
                "enum": ["high", "medium", "low"],
                "description": "分类置信度"
            },
            "reason": {
                "type": "string",
                "description": "分类理由"
            }
        },
        "required": ["department", "confidence", "reason"]
    }
}]

# 调用 API 时指定 tool_choice
response = client.messages.create(
    model="claude-sonnet-4-5-20250514",
    tools=tools,
    tool_choice={"type": "tool", "name": "classify_event"},
    messages=[{"role": "user", "content": "小区门口路灯坏了三天"}]
)

# 返回结果直接是结构化数据，无需解析
```

### 7.4 何时用 Prompt 方式，何时用 API 方式？

| 场景 | 推荐方式 | 理由 |
|------|---------|------|
| **快速原型验证** | Prompt | 无需写代码，快速迭代 |
| **简单输出（1-3个字段）** | Prompt | API 开销不值得 |
| **生产环境** | Structured Output API | 稳定性有保证 |
| **复杂嵌套结构** | Structured Output API | Prompt 难以控制 |
| **需要强类型约束** | Structured Output API | 枚举、数值范围等 |

---

## 八、复杂任务拆解

### 6.1 为什么要拆解？

复杂任务在单个 Prompt 中容易出错：
- 上下文太长，模型容易「忘记」
- 多个步骤混在一起，质量下降
- 出错时难以定位问题

### 6.2 拆解策略

**串行拆解**：步骤依次执行
```
Prompt1: 提取关键信息 → 结果1
Prompt2: 基于结果1进行分析 → 结果2
Prompt3: 基于结果2生成报告 → 最终结果
```

**并行拆解**：独立任务同时执行
```
Prompt1: 分析A方面 → 结果A
Prompt2: 分析B方面 → 结果B     → 合并 → 最终结果
Prompt3: 分析C方面 → 结果C
```

**树形拆解**：先总后分
```
Prompt1: 整体分类 → 类别
├── 类别1 → Prompt2a → 结果1
├── 类别2 → Prompt2b → 结果2
└── 类别3 → Prompt2c → 结果3
```

### 6.3 示例：风险研判报告生成

**原始需求**：根据多源数据生成风险研判报告

**拆解方案**：
```
Prompt1 [信息提取]: 从原始数据中提取关键风险指标
    ↓
Prompt2 [风险评估]: 基于指标判断风险等级和类型
    ↓
Prompt3 [原因分析]: 分析风险形成的原因链
    ↓
Prompt4 [建议生成]: 根据风险分析给出处置建议
    ↓
Prompt5 [报告整合]: 将以上内容整合为结构化报告
```

### 6.4 Chain of Thought (CoT)：让模型「想清楚再说」

> 面试必考：「什么是 CoT？为什么有效？」

**什么是 CoT？**

CoT（思维链，Chain of Thought）是让模型在给出最终答案前，先输出推理过程。

**示例对比**：

**Zero-shot（直接问）**：
```
问：一个农场有 15 只鸡，卖掉 6 只，又买回 3 只，现在有几只？
答：12 只 ❌（跳步出错）
```

**CoT（加一句「请一步步思考」）**：
```
问：一个农场有 15 只鸡，卖掉 6 只，又买回 3 只，现在有几只？请一步步思考。
答：
1. 初始：15 只
2. 卖掉 6 只：15 - 6 = 9 只
3. 买回 3 只：9 + 3 = 12 只
最终答案：12 只 ✅
```

**为什么 CoT 有效？**

| 原因 | 解释 |
|------|------|
| **激活推理路径** | 让模型「说出来」中间步骤，避免跳步出错 |
| **自我检验** | 输出过程中模型可以「看到」自己的推理，有机会纠正 |
| **复杂度分解** | 把一个复杂问题拆成多个简单步骤 |

**CoT 的几种用法**：

| 方法 | 示例 | 适用场景 |
|------|------|---------|
| **Zero-shot CoT** | 加一句「Let's think step by step」| 简单推理 |
| **Few-shot CoT** | 给出带推理过程的示例 | 复杂推理 |
| **Self-Consistency** | 多次生成，投票选最多的答案 | 需要高准确率 |

**使用场景**：
- 数学/逻辑推理
- 多步骤分析
- 需要解释推理过程的场景
- 复杂决策（如风险研判）

**面试回答模板**：
> CoT 通过让模型输出中间推理步骤，激活更深的推理路径。原理是模型在生成过程中可以「看到」自己的中间结果，相当于有了草稿纸，复杂问题被分解成简单步骤，降低了出错概率。

### 8.5 CoT 家族演进（2025-2026）

基础 CoT 已演进出多种变体，应对不同场景：

| 方法 | 核心思想 | 适用场景 |
|------|---------|---------|
| **Zero-shot CoT** | 加一句「Let's think step by step」| 简单推理 |
| **Few-shot CoT** | 给出带推理过程的示例 | 复杂推理 |
| **Tree of Thought (ToT)** | 多路径探索，选最优解 | 需要回溯的问题 |
| **Self-Consistency** | 多次采样，投票选最多的答案 | 需要高准确率 |
| **ReAct** | Reasoning + Acting，推理与行动交替 | Agent 场景 |

**Tree of Thought 示例**：
```
问题：如何从 A 点到 B 点最快？

思路1：坐地铁 → 预计40分钟 → 但需要换乘2次
思路2：打车 → 预计25分钟 → 但可能堵车
思路3：骑车 → 预计35分钟 → 天气不好不适合

评估：考虑到今天下雨，排除思路3；考虑到早高峰，思路2风险高
最终选择：思路1（地铁）
```

**ReAct 模式**（Agent 必备）：
```
Thought: 我需要查询天气来决定出行方式
Action: 调用天气 API
Observation: 今天有雨，气温 15°C

Thought: 下雨不适合骑车，需要查询地铁路线
Action: 调用地图 API
Observation: 地铁需要换乘2次，预计40分钟

Thought: 信息足够了，可以给出建议
Answer: 建议乘坐地铁，预计40分钟到达
```

> **趋势**：2025 年后，单纯的 Prompt 设计越来越多地与 Agent、Tool Use 结合。纯 Prompt 场景在减少，「Prompt + 工具调用」成为主流。

### 8.6 Thinking Mode（o1/o3 模式）

**什么是 Thinking Mode？**

OpenAI o1/o3 系列模型引入了「Thinking Mode」——模型在输出最终答案前，会先在 `<thinking>` 标签中输出完整的推理过程。

```
<thinking>
用户问的是北京到上海的交通方式选择。
需要考虑：时间、成本、舒适度
- 飞机：2小时，但算上值机/安检需要4-5小时
- 高铁：4.5小时，准点率高，市区到市区
- 自驾：12小时，太累

综合考虑商务出行场景，高铁是最佳选择。
</thinking>

建议乘坐高铁。理由：总耗时和飞机相当（考虑机场流程），但准点率更高，且可以在车上办公。
```

**Thinking Mode vs CoT**

| 维度 | CoT（传统） | Thinking Mode（o1/o3） |
|------|------------|----------------------|
| **触发方式** | 需要用户在 Prompt 中要求 | 模型自动执行 |
| **输出位置** | 推理过程和答案混在一起 | 推理过程在 `<thinking>` 标签内，与答案分离 |
| **可见性** | 用户可见 | 可配置为对用户隐藏 |
| **成本** | 推理 Token 计入输出 | 推理 Token 单独计费，通常更贵 |

**产品经理需要知道的**：

1. **何时使用 Thinking Mode**：
   - 需要高准确率的复杂推理（数学、逻辑、代码）
   - 需要模型「深思熟虑」而非快速响应
   - 愿意为质量支付更高成本

2. **何时不需要**：
   - 简单任务（分类、提取、格式转换）
   - 对延迟敏感的场景
   - 成本敏感的高频场景

3. **成本考量**：
   - o1/o3 的 Thinking Token 成本约为普通输出的 3-4 倍
   - 但对于复杂任务，一次深思可能比多次浅尝更划算

---

### 8.7 DSPy：Prompt 自动优化

**认知转变**：Prompt 不一定要人手写，可以让模型来优化。

**什么是 DSPy？**

DSPy 是斯坦福的开源框架，核心思想是：
- 不是写 Prompt，而是定义「输入 → 输出」的签名
- 框架自动生成和优化 Prompt
- 类似于从「手写 CSS」到「Tailwind」的转变

```python
# 传统方式：手写 Prompt
prompt = """
你是一个情感分析专家。
请分析以下文本的情感倾向，输出 positive/negative/neutral。
文本：{text}
"""

# DSPy 方式：定义签名，自动生成 Prompt
class SentimentClassifier(dspy.Signature):
    text = dspy.InputField()
    sentiment = dspy.OutputField(desc="positive, negative, or neutral")

classifier = dspy.Predict(SentimentClassifier)
result = classifier(text="这个产品太棒了！")
```

**PM 为什么需要知道 DSPy？**

| 场景 | 意义 |
|------|------|
| **与开发沟通** | 知道 Prompt 可以自动优化，不必纠结于「咒语式」写法 |
| **评估方案** | 当开发提议「用 DSPy 自动优化」时，你能理解这意味着什么 |
| **趋势认知** | 「手搓 Prompt」正在被「定义目标 + 自动优化」取代 |

**DSPy 适用场景**：
- 需要大量 Prompt 迭代的场景
- 有明确评估指标的任务（分类准确率、提取完整度）
- 开发资源充足，愿意投入自动化

**DSPy 不适用场景**：
- 快速原型验证
- 创意类任务（没有明确「正确答案」）
- 团队不熟悉 Python

> **关键认知**：「咒语式 Prompt」（如「请深呼吸」「以此为极重要任务」）已经过时。现代模型智商足够高，复杂的「催眠咒语」只会浪费 Token。正确的做法是：结构化定义目标，而不是哄骗模型。

---

## 九、从 Prompt 到 Agent：Tool Use

### 9.1 为什么 Prompt 不够用了？

纯 Prompt 的局限：
- 无法获取实时信息（天气、股价、数据库）
- 无法执行操作（发邮件、写文件、调用 API）
- 无法进行复杂计算（精确数学运算）

**解决方案**：让模型调用外部工具（Tool Use / Function Calling）

### 9.2 Tool Use 基本流程

```
用户问题 → 模型判断是否需要工具 → 调用工具 → 获取结果 → 模型整合回答
```

**示例**：
```
用户：北京今天天气怎么样？

模型思考：这个问题需要实时天气数据，我应该调用天气工具
模型输出：{"tool": "get_weather", "params": {"city": "北京"}}

系统执行工具，返回：{"weather": "多云", "temp": "12°C", "humidity": "45%"}

模型整合：北京今天多云，气温12°C，湿度45%，适合外出。
```

### 9.3 Tool Use 与 Prompt 的关系

| 层次 | 职责 | 示例 |
|------|------|------|
| **System Prompt** | 定义 AI 角色、可用工具、行为规范 | 「你是天气助手，可以调用天气 API」|
| **Tool 定义** | 定义每个工具的输入输出格式 | 天气 API 需要 city 参数，返回 weather/temp |
| **User Message** | 用户的具体问题 | 「北京今天天气怎么样」|
| **模型决策** | 判断是否需要工具、调用哪个工具 | 决定调用 get_weather |

### 9.4 产品经理需要知道的

| 知识点 | 为什么重要 |
|--------|-----------|
| **工具定义** | 你需要定义产品中 AI 可以调用哪些工具 |
| **工具边界** | 哪些操作允许 AI 直接执行，哪些需要人工确认 |
| **错误处理** | 工具调用失败时如何降级 |
| **成本控制** | 工具调用会增加 API 调用次数和成本 |

> **延伸**：Tool Use 是 Agent 的基础。如果你要设计 Agent 类产品，必须掌握 Tool Use。详见 No.6_Agent概念。

---

## 十、Prompt 迭代优化

### 7.1 迭代方法论

```
写初版 → 测试 → 发现问题 → 分析原因 → 修改 → 再测试 → ...
```

### 7.2 常见问题及优化方向

| 问题 | 可能原因 | 优化方向 |
|------|---------|---------|
| 输出不稳定 | 任务描述模糊 | 更明确的指令 |
| 格式不对 | 缺少格式约束 | 加强输出格式说明 |
| 内容跑偏 | 缺少边界约束 | 增加「不要做什么」 |
| 质量不够 | 缺少示例 | 增加 Few-shot |
| 太啰嗦 | 没限制长度 | 加字数限制 |

### 7.3 对比分析框架

针对同一任务，写 3 个版本 Prompt，对比分析：

| 维度 | 版本1 | 版本2 | 版本3 |
|------|-------|-------|-------|
| 核心策略 | Zero-shot | Few-shot | CoT |
| 格式控制 | 弱 | 中 | 强 |
| 输出质量 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
| 稳定性 | 60% | 80% | 95% |
| Token消耗 | 低 | 中 | 高 |

---

## 八、实战场景

### 8.1 城市事件分类

**业务场景**：12345热线/城市大脑事件自动分类与流转

**核心挑战**：
- 多分类（10-20个部门/事件类型）
- 边界模糊（一个事件可能涉及多个部门职责）
- 需要稳定输出以支撑自动派单

### 8.2 风险研判报告

**业务场景**：基于数据自动生成风险研判报告

**核心挑战**：
- 输入数据复杂
- 输出格式固定
- 需要推理过程

### 8.3 会议纪要提取

**业务场景**：从会议转录中提取结构化纪要

**核心挑战**：
- 输入是长文本
- 需要提取多个维度（议题、结论、待办）
- 发言人归属

---

## 十二、学习节点说明

基于以上内容，本项目划分为 10 个学习节点：

### A层：基础能力

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **A1** | Prompt 结构与要素：掌握完整 Prompt 的 6 要素 | 为一个 ToG 场景写完整 Prompt 并标注每个要素的作用 |
| **A2** | System Prompt 架构：理解系统级指令的设计 🚧 | 为城市事件分类助手设计 System Prompt |
| **A3** | Few-shot Learning：用示例教模型 | 设计 3-5 个示例让模型学会你指定的输出格式 |

### B层：进阶技巧

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **B1** | 结构化输出控制：Prompt 方式 vs API 方式 | 同一任务分别用两种方式实现，对比稳定性 |
| **B2** | 复杂任务拆解 + CoT 家族：多步骤推理设计 | 为风险研判报告设计 Prompt 链，使用 ReAct 模式 |
| **B3** | Thinking Mode：o1/o3 深度推理 🆕 | 分析 Thinking Mode 和 CoT 的区别，设计适用场景 |
| **B4** | Prompt 迭代优化：同任务多版本对比 | 3 版本对比分析 |

### C层：实战应用

| 节点 | 核心内容 | 验证输出 |
|------|---------|---------|
| **C1** | Tool Use 基础：理解 Prompt 与工具调用的关系 | 设计一个带工具调用的 Prompt 方案 |
| **C2** | DSPy 认知：理解 Prompt 自动优化 🆕 | 解释 DSPy 的核心思想，判断何时适合使用 |
| **C3** | 实战综合：3 个场景的 Prompt 设计 | ① 城市事件分类 ② 风险研判报告 ③ 会议纪要提取 |

---

## 十三、验收标准

学完本项目后，你应该能够：

- [ ] 设计包含 System Prompt + User Message 的完整 Prompt 架构
- [ ] 用 Few-shot 让模型学会特定输出格式
- [ ] 让模型稳定输出 JSON/Markdown，10次至少9次格式正确
- [ ] 理解 Structured Output API 的使用场景，能判断何时用 Prompt 方式、何时用 API 方式
- [ ] 把复杂任务拆成多步骤 Prompt，能使用 CoT 和 ReAct 模式
- [ ] 针对同一任务写3个版本 Prompt 并解释优劣
- [ ] 理解 Tool Use 的基本概念，能设计带工具调用的 Prompt 方案
- [ ] 完成 3 个实操任务（城市事件分类、风险研判报告生成、会议纪要提取）

---

## 十一、延伸阅读

### 官方资源
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)

### 推荐文章
- 《Prompt Engineering 完全指南》— 系统性入门
- 《大模型时代的产品经理》— AI PM 视角

---

## 十五、思考问题

读完这篇导论，尝试不看上文回答：

1. **System Prompt 和传统的「角色设定」有什么区别？为什么要分离？**

2. **Structured Output API 相比 Prompt 方式有什么优势？什么场景下仍然应该用 Prompt 方式？**

3. **CoT、Tree of Thought、ReAct 分别适用于什么场景？**

4. **Thinking Mode（o1/o3）和传统 CoT 有什么区别？什么场景值得用 Thinking Mode？**

5. **「咒语式 Prompt」为什么过时了？现代 Prompt 设计的正确方向是什么？**

6. **DSPy 的核心思想是什么？PM 为什么需要知道这个？**

7. **如果你要设计一个「查询城市实时数据」的 AI 功能，需要 Tool Use 吗？为什么？**

8. **如果一个 Prompt 输出不稳定，你会从哪些方向优化？**

---

> **下一步**：进入 A1 节点，学习 Prompt 的基本结构与要素。
