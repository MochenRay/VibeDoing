---
node: A2
title: 向量与Embedding
status: 已掌握
mastered_date: 2026-01-29
last_reviewed: 2026-01-29
next_review: 2026-02-08
error_count: 1
tags: [RAG, Embedding, 向量检索, 语义相似度, 检索错误vs生成错误]
---

# A2. 向量与Embedding

## 核心概念

### 向量 vs Embedding（关键区分）

**RAG系统里涉及两种模型**：

| 维度 | Embedding模型 | 大模型（LLM）|
|------|---------------|-------------|
| **职责** | 文本 → 向量 | 理解和生成文本 |
| **输入** | 一段文本 | 问题+上下文 |
| **输出** | 一串数字（向量）| 一段文本（回答）|
| **能力** | 语义相似度判断（有限）| 深度理解、推理、改写 |
| **成本** | 低（几厘钱/1000 tokens）| 高（几分到几毛/1000 tokens）|
| **在RAG中的作用** | 负责「找」（检索相关文档）| 负责「读」和「写」（理解文档+生成回答）|

**注意**：它们是两个完全不同的东西，不要混淆！

---

### 向量是什么？

**向量（Vector）**：一组数字，表示高维空间中的一个点。

```
文本："人工智能很有趣"
向量：[0.12, -0.34, 0.56, ..., 0.78]  （通常768-1536维）
```

### Embedding是什么？

**Embedding**：把文本转换成向量的过程，由Embedding模型完成。

**核心直觉**：语义相近的文本，向量在空间中的位置也相近。

```
"人工智能" 的向量 ≈ "AI" 的向量 ≈ "机器学习" 的向量
         ↑ 它们在向量空间中距离很近

"人工智能" 的向量 ≠ "今天天气" 的向量
         ↑ 它们在向量空间中距离很远
```

---

## 类比理解

### 类比1：向量就像GPS坐标

- **北京的坐标** (39.9, 116.4) 和 **天津的坐标** (39.1, 117.2) 很接近
- **北京的坐标** 和 **纽约的坐标** (40.7, -74.0) 相差很远

**Embedding就是给每段文本分配一个「语义坐标」**——语义相近的文本，坐标也相近。

真实的向量不是2维（经纬度），而是768维、1536维的高维空间，但原理相同。

### 类比2：相对距离

苹果和梨在高维空间中的距离比苹果和西瓜更近（因为更相似），但如果是苹果和汽车的话，那苹果和西瓜已经算近的了。

---

## Embedding是怎么训练出来的？

### 核心思想：对比学习（Contrastive Learning）

训练目标：
- **相似的文本** → 向量距离**拉近**
- **不同的文本** → 向量距离**推远**

### 训练过程

```
1. 准备训练数据：
   - 正样本对：语义相似的文本对
     例："人工智能" 和 "AI技术"
   - 负样本对：语义不同的文本对
     例："人工智能" 和 "今天天气"

2. 训练循环：
   - 模型把两段文本都转成向量
   - 如果是正样本对 → 调整参数让向量更近
   - 如果是负样本对 → 调整参数让向量更远
   - 重复几百万次

3. 训练结果：
   - 模型学会了「语义 → 向量位置」的映射规则
```

### 面试回答模板

> Embedding模型通过对比学习训练。训练目标是让语义相似的文本向量距离近，不相似的距离远。模型看了大量的正负样本对后，学会了把语义关系映射到向量空间的位置关系。

---

## 为什么RAG需要向量？

### 传统关键词搜索的问题

- 用户说："提升销售业绩"
- 文档里写："增加营收"
- 没有相同的字 → 搜不到 ❌

### 向量检索的优势

- 把问题和文档都转成向量
- "提升销售业绩"的向量 和 "增加营收"的向量很接近
- 能找到 ✅

**核心差异**：
- 关键词搜索：字面匹配（必须有相同的字）
- 向量检索：语义匹配（意思相近就能找到，即使用词不同）

---

## 实战场景：城市政策问答系统

### 场景

用户问："**外地人**能申请公租房吗？"
文档写："**非本市户籍人员**公共租赁住房申请条件"

### 问题

如果Embedding模型训练语料里没见过"外地人"和"非本市户籍人员"的对应关系，可能检索不到。

### 解决方案

1. **换更好的Embedding模型**（训练语料覆盖更广）
2. **增加Top-K数量**（治标不治本）
3. **Query Rewriting**（用大模型先把口语改成书面语）
   - 用户问题 → 大模型改写 → "非本市户籍人员是否可以申请公共租赁住房？"
   - 改写后的问题 → Embedding模型 → 向量 → 检索
4. **混合检索**（向量检索 + 关键词检索结合）

---

## 与A1的关系

- **A1讲的是整体流程**（离线索引 + 在线查询）
- **A2讲的是关键技术**（怎么把文本变成可检索的向量）
- 没有A2的Embedding，A1的"相似度检索"就无法实现

Embedding是RAG的必要环节，如果不向量化，RAG就不成立。

---

## 关键要点

1. ✅ Embedding模型 ≠ 大模型（前者只做文本→向量，后者理解+生成）
2. ✅ 向量是结果（数组），Embedding是过程（文本转向量）
3. ✅ 语义相近的文本，向量在空间中也相近（GPS坐标类比）
4. ✅ Embedding模型通过对比学习训练（拉近相似，推远不同）
5. ✅ 向量检索能找到同义表达（突破字面限制）
6. ✅ Query Rewriting用大模型改写问题，弥补Embedding模型的语料覆盖不足

---

## 验证表现

- **错误次数**：0
- **理解亮点**：
  - 准确区分了Embedding模型和大模型的职责
  - 理解了向量检索的核心优势（同义词识别）
  - 意识到了Embedding的代价（成本、语料覆盖问题）
  - 能从产品视角分析问题（用户表达差异）

---

## 🚫 我的错误记录

### 错误1：混淆"检索精度问题"和"生成问题"

**场景**：城市政策问答系统，用户问"低保怎么申请"，系统返回"低保标准调整通知"

**我的判断**：生成问题

**实际情况**：检索错误（检索精度不足）
- 系统找到了"低保"相关文档 ✅
- 但不够精准（找到了"标准"而不是"申请"）❌
- 这是**检索阶段就找错了文档**，不是生成阶段的问题

**区分关键**：
- 检索错误：文档就不对（不相关 or 不够精准）
- 生成错误：文档对，但大模型理解/生成错了

**为什么犯错**：
- 看到"答非所问"就觉得是生成问题
- 没有仔细分析"文档本身对不对"

**正确做法**：
- 先判断：检索到的文档是否是用户想要的？
- 如果文档不对 → 检索错误
- 如果文档对但答案错 → 生成错误

---

## 💡 实操验证高光

**城市政策问答系统优化方案**：
- ✅ 准确识别出"残疾人补助 vs 扶持资金"是语义覆盖度问题
- ✅ 提出混合检索（向量+关键词）方案，成本意识强
- ✅ 分析技术问题时想到"用户反复提问导致embedding调用增多"
- ⚠️ 技术问题分析不够全面（缺少缓存/代码bug排查维度）
- ⚠️ 运营问题误判为生成问题（实际是检索精度问题）

**方案权衡亮点**：
选择混合检索作为优先方案，理由：
- 成本相对低
- 能同时解决产品问题（同义词识别）和运营问题（精准匹配）
- 产品视角清晰

---

## 下一步

A2 已完全掌握，进入 B1（文档分块策略）学习。
