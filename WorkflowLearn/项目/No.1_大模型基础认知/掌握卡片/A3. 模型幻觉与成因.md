# A3. 模型幻觉与成因

---
status: mastered
mastered_date: 2026-01-22
last_modified: 2026-01-22
next_review: 2026-01-25
---

## 🎯 核心概念

### 幻觉是什么
大模型生成**看起来合理、但实际错误或虚构**的内容。

### 三种幻觉类型

| 类型 | 描述 | 示例 |
|------|------|------|
| **事实错误** | 说出不存在/不正确的事实 | 「华为 Mate 70 于 2025 年 3 月发布」（实际是 2024 年 11 月）|
| **虚构引用** | 编造不存在的来源 | 「根据 Stanford 2024 年发表的《RAG: A Survey》...」|
| **逻辑矛盾** | 前后不一致 | 先说 A 成本更低，后说 B 成本优势更明显 |

### 幻觉成因
- 模型是「预测下一个词」，不是「查表回答」
- 没有事实核查机制
- 倾向于给出答案，而非说「不知道」

---

## ⚠️ 关键认知：「限定数据范围」不能杜绝幻觉

### 常见误区
> 给了文档 → 模型照着答 → 不会出错 ❌

### 实际情况
> 给了文档 → 模型**参考**文档 + 训练知识 → 可能混淆

**原因**：模型没有「只看文档」的硬开关。即使用 RAG 塞入相关内容，生成时仍基于全部已知信息预测。

### 事实错误的三种子类型（政策场景）

| 子类型 | 说明 | 危险程度 |
|--------|------|---------|
| 张冠李戴 | 把 A 政策内容混到 B 政策 | 高 |
| 数字篡改 | 关键数字不准确 | 高 |
| **凭空补全** | 文档没写的，模型自己「推断」| **最高** |

---

## 💡 硬开关 vs 软约束

| 类型 | 说明 | 效果 |
|------|------|------|
| **硬开关** | 技术层面强制，模型无法绕过 | 100% 生效 |
| **软约束** | Prompt 指令，模型「尽量遵守」| 大概率生效，可能被忽略 |

**Prompt 限制 = 软约束**，不是硬开关。

### NotebookLM 为什么像「硬开关」？

不是模型能力，是**产品设计 + Prompt 工程 + 后处理**共同实现：
- 严格的 System Prompt
- 只把用户上传内容作为 Context
- 可能的输出校验/过滤

即使如此，也不能保证 100% 不出错——只是概率大幅降低。

---

## 📋 缓解策略（按优先级）

| 优先级 | 方法 | 效果 |
|--------|------|------|
| 1 | Prompt 限制：「没有就说文档未提及」| 减少凭空补全 |
| 2 | 强制引用原文 | 便于用户核对 |
| 3 | Temperature = 0 | 减少随机发挥 |
| 4 | RAG 溯源：返回原文 chunk | 可追溯 |
| 5 | 二次校验 | 减少数字错误 |
| 6 | 人工审核 | 兜底 |

---

## 📚 延伸

- 幻觉 vs Temperature：Temperature 高导致措辞变化，不是编造事实的主因
- ToG 场景幻觉后果严重，必须多层防护
