---
status: mastered
mastered_date: 2026-01-15
review_count: 1
last_review: 2026-01-16
next_review: 2026-01-19
---

# 掌握卡片：A2. 相似度计算与ANN算法

## 🧠 我的理解

> 余弦相似度更像是考虑两个图是不是等比例放大，100m²等腰直角三角形和1m²等腰直角三角形相似度最高，因为形状完全一致；欧氏距离把各个方向坐标轴上的值加和比较，对形状关注度低，面积影响大；点积是方向和大小的乘积效应，"力量大打不准"和"力量小但精准"造成的伤害差不多。

> RAG系统为每篇文章生成向量雷达图，通过形状、大小将几百万篇文档归类聚拢成"堆"，同一堆的文件相似相关。然后层层细分让堆越来越小、越来越准，最终找到Top-K相关文档。

> Embedding选型是否合理，决定了ANN效果的上限。

## 🔗 类比挂钩

**"三角形类比"**（用户原创）
- 余弦相似度：100m²和1m²的等腰直角三角形相似度最高，只看形状不看大小
- 欧氏距离：各维度值加和比较，面积影响大
- 点积：方向 × 大小的乘积效应

**"分堆类比"**
- ANN = 把几百万文档按雷达图形状聚拢成堆
- 层层细分 = 堆越来越小、越来越准
- Top-K = 近似搜索，不追求100%精确

**"图书馆分区"**（IVF）
- 先确定"计算机科学区"，再确定"人工智能架"

**"朋友的朋友"**（HNSW）
- 通过社交网络层层跳转逼近目标

## ⚠️ 常见误区

- **误区**：ANN准确率低 = ANN算法问题
- **真相**：可能是Embedding质量差，需要先检查Embedding再调ANN参数

- **误区**：暴力搜索一定更准确
- **真相**：暴力搜索100%精确但太慢，ANN用近似换速度，在RAG场景中够用

## 🚫 我的错误记录

- **场景**：排查ANN准确率低的问题
- **错误**：只考虑了"分堆不够细"，漏掉了Embedding质量这个根因
- **归因**：对检索链路不熟悉，不知道Embedding是上游
- **修正**：排查顺序应是：先检查Embedding质量，再调ANN参数

## 💡 验证高光

- 用三角形类比精准解释三种相似度度量
- 务实的工程思维："先确认5秒能不能暴力搜索500万篇"
- 理解Embedding决定ANN效果上限

## 📖 源真理定义

> **相似度计算**：衡量两个向量相似程度的方法，主要有余弦相似度（只看方向）、欧氏距离（看点对点差值）、点积（综合方向和大小）。
> 
> **ANN（近似最近邻）**：用"先粗筛后细找"的策略实现高速向量检索，主要算法有HNSW（图跳转）和IVF（聚类分桶）。

## 🧱 关联知识

- **前置节点**：[[A1. Embedding原理]]
- **后置节点**：[[A3. Chunking分块策略]]
- **关键关联**：Embedding质量决定ANN效果上限

## 💪 实操挑战

因掌握验证中已充分展示理解深度（三角形类比 + 务实工程判断），跳过独立实操，直接通过。
